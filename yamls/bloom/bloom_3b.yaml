task: &task billsum
max_seq_length: 128  # This is very short! just an FSDP test
model_type: huggingface
model_name: &model_name bigscience/bloom-3b
tokenizer_name: &tokenizer_name bigscience/bloom-3b
# Run Name
run_name: &run_name EXAMPLE
# Model
model:
  name: *model_name
  use_pretrained: true
  pretrained_model_name: *model_name
  tokenizer_name: *tokenizer_name
  debug: true

# need to test lr schedules on lex-glue
scheduler:
  name: constant_with_warmup
  t_warmup: 100ba  # guess

optimizer:
  name: decoupled_adamw
  lr: 3.0e-4
  betas:
    - 0.9
    - 0.98
  eps: 1.0e-06
  weight_decay: 1.0e-5

max_duration: 30ep
eval_interval: 1ba
grad_clip_norm: -1.0

global_train_batch_size: 4
global_eval_batch_size: 4

# FSDP
fsdp_config:
  sharding_strategy: FULL_SHARD
  min_params: 1e8
  mixed_precision: DEFAULT
  activation_checkpointing: false
  activation_cpu_offload: false
  verbose: true

# System
seed: 42
grad_accum: auto
precision: bf16
# Logging
progress_bar: true
log_to_console: true
callbacks:
  speed_monitor:
    window_size: 500
  lr_monitor: {}
# loggers:
#   wandb: {}
# Checkpoint to local filesystem or remote object store
# save_interval: 1ep
# save_num_checkpoints_to_keep: 1
# need to set up an s3 folder for myself
# save_folder: s3://mosaicml-internal-checkpoints-shared/sam/lex-glue/${task}/${model_name}/${run_name}/checkpoints
